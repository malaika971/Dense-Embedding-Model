# Dense-Embedding-Model
Trained a dense embedding model to learn meaningful  embeddings from the dataset (that has been extracted using web-crawling from State Bank Of Pakistan (SBP) and pre-processed )


### **Objective: Develop embeddings that capture semantic relationships within the data..**

The goal is to train a dense embedding model to learn meaningful embeddings from the dataset that is extracted (from State Bank Of Pakistan) and pre-processed.

### Tools and Libraries used
- NLTK
- WORD2VEC
- GENSIM
- MATPLOTLIB
- PANDAS
- NUMPY
- SKLEARN

  ### Steps
  1. Data Preparation
  2. Pre-Processing
        - Lower-Casing
        - Removing Punctuation
        - Creating Lemmas
        - Creating word tokens
          
3. Defining Model Hyperparameters
4. Training Word2vec model
5. Model Evaluation (Cosine Similarity)
---

[Info-Graphics1.pdf](https://github.com/user-attachments/files/18469092/Info-Graphics1.pdf)










[Info-Graphics2.pdf](https://github.com/user-attachments/files/18469094/Info-Graphics2.pdf)
